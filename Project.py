# -*- coding: utf-8 -*-
"""Untitled82.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dw9oJaEV1ChDN4J7liizGAUZ8DqtdqGR
"""

'''Car Price Prediction
Outlines
Project target : Predict Used car price based on car specifications

1.Data cleaning
2.feature engineering
3.Getting more insights
4.Data Pre-processing
5.Modeling
6.Evalution'''

# Packages for EDA
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("/content/Car_Price_Prediction.csv")       # Open dataset
print(df)

df.columns

df.info()

df.nunique()

df.isnull().sum()

#Drop "New_Price" column because most of them is null
df=df.drop(['New_Price'],axis=1)
display(df.head())

df.duplicated().sum()

df = df.drop_duplicates()
df.duplicated().sum()

df.describe()

#  Numerical values mixed with text in (Mileage, Engine, Power) columns.
# in Milage column we have 2 units (kmpl & km/kg)
df['Mileage'] = df['Mileage'].str.replace('kmpl','')
df['Mileage'] = df['Mileage'].str.replace('km/kg','')
df['Engine'] = df['Engine'].str.replace('CC','')
df['Power'] = df['Power'].str.replace('bhp','')

df.info()

# Convert numerical object valued columns into numerical values
df['Mileage']=pd.to_numeric(df['Mileage'])
df['Power']=pd.to_numeric(df['Power'],errors='coerce')

# Replace NaN values using Mode
df['Seats'] = df['Seats'].fillna(df['Seats'].mode()[0])
df['Price'] = df['Price'].fillna(df['Price'].mode()[0])
df['Mileage']=df['Mileage'].fillna(df['Mileage'].mode()[0])
df['Engine']=df['Engine'].fillna(df['Engine'].mode()[0])
df['Power']=df['Power'].fillna(df['Power'].mode()[0])

# Convert float valued columns into integer values
df['Seats']=df['Seats'].apply(np.int64)
df['Price']=df['Price'].apply(np.int64)
df['Mileage']=df['Mileage'].apply(np.int64)
df['Engine']=df['Engine'].apply(np.int64)
df['Power']=df['Power'].apply(np.int64)

df.info()

df.isnull().sum()

# IN Name column We can notice that the first word of the name is (Brand), so let's get it

df["Brand"] = df["Name"].apply(lambda x : x.split()[0])

'''A huge difference here, From this columns we can make a big affect.
    Another observation that first two word can express wich car we want.
      So, let's change name column with just first 2 words.'''
df["Name"] = df["Name"].apply(lambda x : " ".join(x.split()[:2]))

# Use value counts for each column

print(df['Name'].value_counts())
print("-------------------")
print(df['Location'].value_counts())
print("-------------------")
print(df['Year'].value_counts())
print("-------------------")
print(df['Kilometers_Driven'].value_counts())
print("-------------------")
print(df['Fuel_Type'].value_counts())
print("-------------------")
print(df['Transmission'].value_counts())
print("-------------------")
print(df['Owner_Type'].value_counts())
print("-------------------")
print(df['Mileage'].value_counts())
print("-------------------")
print(df['Engine'].value_counts())
print("-------------------")
print(df['Power'].value_counts())
print("-------------------")
print(df['Seats'].value_counts())
print("-------------------")
print(df['Price'].value_counts())

"""# **Mean,Median,Mode,Correlation,Covariance,Variance,Range,Standard Deviation**"""

print("Mean of Dataframe:")
df.mean(axis=0)

print("Median of Dataframe:")
df.median(axis=0)

print("Mode of Dataframe:")
df.mode(axis=0)

print("Correlation of Dataframe:")
print(df.corr())
print(df.corrwith(df, axis=0))

print("Covariance of Dataframe:")
df.cov()

print("Standard Deviation of dataframe:")
df.std(axis=0)

print("Variance of Dataframe:")
df.var(axis=0)

# Use  range for the column

print(" range of Year:",  np.ptp(df['Year']))
print("-------------------")
print(" range of Kilometers_Driven:",  np.ptp(df['Kilometers_Driven']))
print("-------------------")
print(" range of Mileage:",  np.ptp(df['Mileage']))
print("-------------------")
print(" range of Engine:",  np.ptp(df['Engine']))
print("-------------------")
print(" range of Power:",  np.ptp(df['Power']))
print("-------------------")
print(" range of Seats:",  np.ptp(df['Seats']))
print("-------------------")
print(" range of Price:",  np.ptp(df['Price']))

# Skewness and Kurtosis
print("Skewness:")
print(df.skew())
print("--------------------------")
print("Kurtosis:")
print(df.kurt())

print(df.groupby('Brand').size())

print(df.groupby('Transmission')['Name'].count())

print(df.groupby('Owner_Type')['Name'].count())

print(df.groupby('Fuel_Type')['Name'].count())

print(df.groupby('Brand')['Name'].count())

"""#**Graphical Representation**

# **Bar Plot**
"""

plt.figure(figsize=(15,8))
plt.bar(df['Location'],df['Brand'])
plt.xlabel("Location")
plt.ylabel("Brand")
plt.show()

plt.figure(figsize=(10,8))
plt.bar(df['Location'],df['Price'])
plt.xlabel("Location")
plt.ylabel("Price")
plt.show()

plt.figure(figsize=(15,8))
plt.bar(df['Seats'],df['Brand'])
plt.xlabel("Seats")
plt.ylabel("Brand")
plt.show()

sns.barplot(data=df, x="Transmission", y="Mileage",hue="Fuel_Type")
plt.show()

sns.barplot(data=df, y="Brand", x="Seats")
plt.show()

sns.barplot(data=df, x="Fuel_Type", y="Kilometers_Driven",hue="Owner_Type")
plt.show()

"""# **Scatter Plot**"""

plt.figure(figsize=(10,5))
x = df['Price']
plt.scatter(x,y=df['Kilometers_Driven'],c='red',marker='o')
plt.scatter(x,y= df['Seats'],c='b',marker='>')
plt.show()

x=df['Price']
plt.subplot(1, 2, 1)
plt.scatter(x,df['Kilometers_Driven'],c='r',marker='>')
plt.subplot(1, 2, 2)
plt.scatter(x,df['Seats'])
plt.show()

from mpl_toolkits.mplot3d import Axes3D
fig = plt.figure()
ax = fig.add_subplot(111, projection = '3d')

x = df['Price']
y = df['Seats']
z = df['Kilometers_Driven']

ax.scatter(x, y, z)
ax.set_xlabel("Price")
ax.set_ylabel("Seats")
ax.set_zlabel("Kilometers_Driven")

plt.show()

"""# **Histogram**"""

# histograms
plt.figure(figsize=(15,8))
df.hist()
plt.show()

plt.figure(figsize=(16,12))

plt.subplot(3,3,1)
plt.hist(df['Location'])
plt.title("Location")

plt.subplot(3,3,2)
plt.hist(df['Mileage'])
plt.title("Mileage")

plt.subplot(3,3,3)
plt.hist(df['Kilometers_Driven'])
plt.title("Kilometers_Driven")

plt.subplot(3,3,4)
plt.hist(df['Fuel_Type'])
plt.title("Fuel_Type")

plt.subplot(3,3,5)
plt.hist(df['Year'])
plt.title("Year")

plt.subplot(3,3,6)
plt.hist(df['Transmission'])
plt.title("Transmission")

plt.subplot(3,3,7)
plt.hist(df['Seats'])
plt.title("Seats")

plt.subplot(3,3,8)
plt.hist(df['Engine'])
plt.title("Engine")

plt.subplot(3,3,9)
plt.hist(df['Price'])
plt.title("Price")

plt.show()

sns.set(style="whitegrid")
fig,axs = plt.subplots(3,3, figsize = (14,10))
sns.histplot(data=df, x="Price", kde=True, color="skyblue", ax=axs[0, 0])
sns.histplot(data=df, x="Location", kde=True, color="olive", ax=axs[0, 1])
sns.histplot(data=df, x="Mileage", kde=True, color="purple", ax=axs[0,2])
sns.histplot(data=df, x="Year", kde=True, color="gold", ax=axs[1, 0])
sns.histplot(data=df, x="Kilometers_Driven", kde=True, color="teal", ax=axs[1, 1])
sns.histplot(data=df, x="Engine", kde=True, color="purple", ax=axs[1,2])
sns.histplot(data=df, x="Fuel_Type", kde=True, color="teal", ax=axs[2, 0])
sns.histplot(data=df, x="Transmission", kde=True, color="blue", ax=axs[2, 1])
sns.histplot(data=df, x="Seats", kde=True, color="purple", ax=axs[2,2])
fig.tight_layout()

#kernel density estimate (KDE)
sns.set(style="whitegrid")
fig,axs = plt.subplots(2,2, figsize = (10,10))
sns.kdeplot(df["Price"], color="skyblue", ax=axs[0, 0])
sns.kdeplot(df["Year"], color="gold", ax=axs[0, 1])
sns.kdeplot(df["Kilometers_Driven"],color="teal", ax=axs[1, 0])
sns.kdeplot(df["Seats"],color="purple", ax=axs[1,1])
fig.tight_layout()
plt.show()

"""# **Box Plot**

##       Basic Plot
"""

# box plots
plt.figure(figsize=(15,8))
df.plot(kind='box', subplots=True, sharex=False, sharey=False)
plt.show()

fig, axs = plt.subplots(1, 3)
# don't show outlier points
axs[0].boxplot(df['Seats'], 0, '')
axs[0].set_title('Seats')

axs[1].boxplot(df['Kilometers_Driven'], 0, '')
axs[1].set_title('Kilometers_Driven')

axs[2].boxplot(df['Price'], 0, '')
axs[2].set_title('Price')

plt.show()

"""## Horizontal Plot"""

fig, axs = plt.subplots(1, 3)

axs[0].boxplot(df['Seats'], 0, 'rs', 0)
axs[0].set_title('Seats')

axs[1].boxplot(df['Kilometers_Driven'],0, 'rs', 0)
axs[1].set_title('Kilometers_Driven')

axs[2].boxplot(df['Price'], 0, 'rs', 0)
axs[2].set_title('Price')

plt.show()

"""# **Line Plot**"""

sns.lineplot(data=df, x="Mileage", y="Fuel_Type",hue="Owner_Type",style='Owner_Type')
plt.show()

sns.pairplot(df)

"""# **Heat Map**"""

corrMatrix=df.corr()
plt.figure(figsize=(10,5))
sns.heatmap(corrMatrix, annot=True, cmap="viridis")
plt.show()

# Convert categorical values into integer values
from sklearn import preprocessing
le=preprocessing.LabelEncoder()
df['Name']=le.fit_transform(df.Name.values)
df['Location']=le.fit_transform(df.Location.values)
df['Fuel_Type']=le.fit_transform(df.Fuel_Type.values)
df['Transmission']=le.fit_transform(df.Transmission.values)
df['Owner_Type']=le.fit_transform(df.Owner_Type.values)
df['Brand']=le.fit_transform(df.Brand.values)

df.info()

"""# **Data Splitting**"""

x=df.drop(['Price'],axis=1)
y=df['Price']

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.20)
print(x_train.shape)
print(y_train.shape)

print(x_test.shape)
print(y_test.shape)

from sklearn.ensemble import ExtraTreesRegressor
model = ExtraTreesRegressor()
model.fit(x,y)
print(model.feature_importances_)
#plot graph of feature importances for better visualization
feat_importances = pd.Series(model.feature_importances_, index=x.columns)
feat_importances.nlargest(5).plot(kind='barh')
plt.show()

"""# **List of regression algorithms in Machine Learning**

1.Linear Regression

2.Ridge Regression

3.Lasso Regression

4.Logistic Regression

5.Decision Tree Regression

6.Random Forest

7.KNN Model

8.AdaBoost Regression

9.GradientBoosting Regression

10.XGB Regression
"""

from sklearn.linear_model import LinearRegression
from sklearn.linear_model import Ridge,Lasso
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.neighbors import KNeighborsRegressor
from xgboost.sklearn import XGBRegressor
from sklearn.ensemble import GradientBoostingRegressor,AdaBoostRegressor,BaggingRegressor
from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score

"""# **1.Linear Regression**"""

# loading the linear regression model
lr=LinearRegression()
#Now we can fit the model to our dataset
lr.fit(x_train,y_train)

y_pred_train=lr.predict(x_train)       # prediction on Training data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_train,y_pred_train)
print("Mean Absolute Error (MAE)-Train:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_train,y_pred_train)
print("Mean Squared Error (MSE)-Train:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Train:",rmse.round(2))

# R² (R-Squared)
y1=r2_score(y_train,y_pred_train)
print("R squared Error-Train : ",y1)

################################################################################
print("#####################################################################")


y_pred_test=lr.predict(x_test)           # prediction on test data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_test,y_pred_test)
print("Mean Absolute Error (MAE)-Test:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_test,y_pred_test)
print("Mean Squared Error (MSE)-Test:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Test:",rmse.round(2))

# R² (R-Squared)
y2= r2_score(y_test, y_pred_test)
print("R squared Error-Test : ",y2)             # prediction on Test data

plt.scatter(y_train,y_pred_train,label='Train')
plt.scatter(y_test,y_pred_test,label='Test')
plt.title("Linear Regression")
plt.legend()
plt.show()

"""# **2.Ridge Regression**"""

# loading the linear regression model
ridge=Ridge(alpha=1.0)
#Now we can fit the model to our dataset
ridge.fit(x_train,y_train)

y_pred_train=ridge.predict(x_train)       # prediction on Training data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_train,y_pred_train)
print("Mean Absolute Error (MAE)-Train:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_train,y_pred_train)
print("Mean Squared Error (MSE)-Train:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Train:",rmse.round(2))

# R² (R-Squared)
y1=r2_score(y_train,y_pred_train)
print("R squared Error-Train : ",y1)

################################################################################
print("#####################################################################")


y_pred_test=ridge.predict(x_test)           # prediction on test data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_test,y_pred_test)
print("Mean Absolute Error (MAE)-Test:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_test,y_pred_test)
print("Mean Squared Error (MSE)-Test:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Test:",rmse.round(2))

# R² (R-Squared)
y2= r2_score(y_test, y_pred_test)
print("R squared Error-Test : ",y2)             # prediction on Test data

plt.scatter(y_train,y_pred_train,label='Train')
plt.scatter(y_test,y_pred_test,label='Test')
plt.title("Ridge Regression")
plt.legend()
plt.show()

"""# **4.Lasso Regression**"""

lasso=Lasso(alpha = 1.0)
lasso.fit(x_train,y_train)

y_pred_train=lasso.predict(x_train)       # prediction on Training data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_train,y_pred_train)
print("Mean Absolute Error (MAE)-Train:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_train,y_pred_train)
print("Mean Squared Error (MSE)-Train:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Train:",rmse.round(2))

# R² (R-Squared)
y1=r2_score(y_train,y_pred_train)
print("R squared Error-Train : ",y1)

################################################################################
print("#####################################################################")


y_pred_test=lasso.predict(x_test)           # prediction on test data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_test,y_pred_test)
print("Mean Absolute Error (MAE)-Test:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_test,y_pred_test)
print("Mean Squared Error (MSE)-Test:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Test:",rmse.round(2))

# R² (R-Squared)
y2= r2_score(y_test, y_pred_test)
print("R squared Error-Test : ",y2)             # prediction on Test data

plt.scatter(y_train,y_pred_train,label='Train')
plt.scatter(y_test,y_pred_test,label='Test')
plt.title("Lasso Regression")
plt.legend()
plt.show()

print("Linear Regression Model Training Score: ", lr.score(x_train, y_train))
print("Linear Regression Model Testing Score: ",lr.score(x_test, y_test))
print("---------------------------------------------------")
print("Ridge Regression Model Training Score: ",ridge.score(x_train, y_train))
print("Ridge Regression Model Testing Score: ",ridge.score(x_test, y_test))
print("---------------------------------------------------")
print("Lasso Regression Model Training Score: ",lasso.score(x_train, y_train))
print("Lasso Regression Model Testing Score: ",lasso.score(x_test, y_test))

#plot size
plt.figure(figsize=(8,8))
#add plot for ridge regression
plt.plot(ridge.coef_,alpha=0.7,linestyle='none',marker='*',markersize=5,color='red',label=r'Ridge; $\alpha = 10$',zorder=7)

#add plot for lasso regression
plt.plot(lasso.coef_,alpha=0.5,linestyle='none',marker='d',markersize=6,color='blue',label=r'lasso; $\alpha = grid$')

#add plot for linear model
plt.plot(lr.coef_,alpha=0.4,linestyle='none',marker='o',markersize=7,color='green',label='Linear Regression')

#rotate axis
plt.xticks(rotation = 90)
plt.legend()
plt.title("Comparison plot of Ridge, Lasso and Linear regression model")
plt.show()

"""# **4.Logistic Regression**"""

model = LogisticRegression()
model.fit(x_train,y_train)

y_pred_train=model.predict(x_train)       # prediction on Training data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_train,y_pred_train)
print("Mean Absolute Error (MAE)-Train:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_train,y_pred_train)
print("Mean Squared Error (MSE)-Train:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Train:",rmse.round(2))

# R² (R-Squared)
y1=r2_score(y_train,y_pred_train)
print("R squared Error-Train : ",y1)

################################################################################
print("#####################################################################")


y_pred_test=model.predict(x_test)           # prediction on test data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_test,y_pred_test)
print("Mean Absolute Error (MAE)-Test:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_test,y_pred_test)
print("Mean Squared Error (MSE)-Test:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Test:",rmse.round(2))

# R² (R-Squared)
y2= r2_score(y_test, y_pred_test)
print("R squared Error-Test : ",y2)             # prediction on Test data

plt.scatter(y_train,y_pred_train,label='Train')
plt.scatter(y_test,y_pred_test,label='Test')
plt.title("Logistic Regression")
plt.legend()
plt.show()

"""# **5.Decision Tree Regression**"""

dr=DecisionTreeRegressor()
dr.fit(x_train,y_train)

y_pred_train=dr.predict(x_train)       # prediction on Training data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_train,y_pred_train)
print("Mean Absolute Error (MAE)-Train:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_train,y_pred_train)
print("Mean Squared Error (MSE)-Train:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Train:",rmse.round(2))

# R² (R-Squared)
y1=r2_score(y_train,y_pred_train)
print("R squared Error-Train : ",y1)

################################################################################
print("#####################################################################")


y_pred_test=dr.predict(x_test)           # prediction on test data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_test,y_pred_test)
print("Mean Absolute Error (MAE)-Test:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_test,y_pred_test)
print("Mean Squared Error (MSE)-Test:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Test:",rmse.round(2))

# R² (R-Squared)
y2= r2_score(y_test, y_pred_test)
print("R squared Error-Test : ",y2)             # prediction on Test data

plt.scatter(y_train,y_pred_train,label='Train')
plt.scatter(y_test,y_pred_test,label='Test')
plt.title("Decision Tree Regression")
plt.legend()
plt.show()

"""# **6.Random Forest Regression**"""

rf=RandomForestRegressor()
rf.fit(x_train,y_train)

y_pred_train=rf.predict(x_train)       # prediction on Training data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_train,y_pred_train)
print("Mean Absolute Error (MAE)-Train:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_train,y_pred_train)
print("Mean Squared Error (MSE)-Train:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Train:",rmse.round(2))

# R² (R-Squared)
y1=r2_score(y_train,y_pred_train)
print("R squared Error-Train : ",y1)

################################################################################
print("#####################################################################")


y_pred_test=rf.predict(x_test)           # prediction on test data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_test,y_pred_test)
print("Mean Absolute Error (MAE)-Test:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_test,y_pred_test)
print("Mean Squared Error (MSE)-Test:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Test:",rmse.round(2))

# R² (R-Squared)
y2= r2_score(y_test, y_pred_test)
print("R squared Error-Test : ",y2)             # prediction on Test data

plt.scatter(y_train,y_pred_train,label='Train')
plt.scatter(y_test,y_pred_test,label='Test')
plt.title("Random Forest Regression")
plt.legend()
plt.show()

"""# **7.KNN Model**"""

knn=KNeighborsRegressor(n_neighbors=3)
knn.fit(x_train, y_train)

y_pred_train=knn.predict(x_train)       # prediction on Training data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_train,y_pred_train)
print("Mean Absolute Error (MAE)-Train:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_train,y_pred_train)
print("Mean Squared Error (MSE)-Train:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Train:",rmse.round(2))

# R² (R-Squared)
y1=r2_score(y_train,y_pred_train)
print("R squared Error-Train : ",y1)

################################################################################
print("#####################################################################")


y_pred_test=knn.predict(x_test)           # prediction on test data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_test,y_pred_test)
print("Mean Absolute Error (MAE)-Test:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_test,y_pred_test)
print("Mean Squared Error (MSE)-Test:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Test:",rmse.round(2))

# R² (R-Squared)
y2= r2_score(y_test, y_pred_test)
print("R squared Error-Test : ",y2)             # prediction on Test data

plt.scatter(y_train,y_pred_train,label='Train')
plt.scatter(y_test,y_pred_test,label='Test')
plt.title("KNN Regression")
plt.legend()
plt.show()

"""# **8.AdaBoost Regression**"""

ad=AdaBoostRegressor()
ad.fit(x_train,y_train)

y_pred_train=ad.predict(x_train)       # prediction on Training data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_train,y_pred_train)
print("Mean Absolute Error (MAE)-Train:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_train,y_pred_train)
print("Mean Squared Error (MSE)-Train:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Train:",rmse.round(2))

# R² (R-Squared)
y1=r2_score(y_train,y_pred_train)
print("R squared Error-Train : ",y1)

################################################################################
print("#####################################################################")


y_pred_test=ad.predict(x_test)           # prediction on test data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_test,y_pred_test)
print("Mean Absolute Error (MAE)-Test:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_test,y_pred_test)
print("Mean Squared Error (MSE)-Test:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Test:",rmse.round(2))

# R² (R-Squared)
y2= r2_score(y_test, y_pred_test)
print("R squared Error-Test : ",y2)             # prediction on Test data

plt.scatter(y_train,y_pred_train,label='Train')
plt.scatter(y_test,y_pred_test,label='Test')
plt.title("AdaBoost Regression")
plt.legend()
plt.show()

"""# **9.Gradient Boosting Regression**"""

gr=GradientBoostingRegressor()
gr.fit(x_train, y_train)

y_pred_train=gr.predict(x_train)       # prediction on Training data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_train,y_pred_train)
print("Mean Absolute Error (MAE)-Train:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_train,y_pred_train)
print("Mean Squared Error (MSE)-Train:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Train:",rmse.round(2))

# R² (R-Squared)
y1=r2_score(y_train,y_pred_train)
print("R squared Error-Train : ",y1)

################################################################################
print("#####################################################################")


y_pred_test=gr.predict(x_test)           # prediction on test data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_test,y_pred_test)
print("Mean Absolute Error (MAE)-Test:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_test,y_pred_test)
print("Mean Squared Error (MSE)-Test:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Test:",rmse.round(2))

# R² (R-Squared)
y2= r2_score(y_test, y_pred_test)
print("R squared Error-Test : ",y2)             # prediction on Test data

plt.scatter(y_train,y_pred_train,label='Train')
plt.scatter(y_test,y_pred_test,label='Test')
plt.title("Gradient Boosting Regression")
plt.legend()
plt.show()

"""# **10.XGB Regressor**"""

xgb=XGBRegressor()
xgb.fit(x_train,y_train)

y_pred_train=xgb.predict(x_train)       # prediction on Training data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_train,y_pred_train)
print("Mean Absolute Error (MAE)-Train:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_train,y_pred_train)
print("Mean Squared Error (MSE)-Train:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Train:",rmse.round(2))

# R² (R-Squared)
y1=r2_score(y_train,y_pred_train)
print("R squared Error-Train : ",y1)

################################################################################
print("#####################################################################")


y_pred_test=xgb.predict(x_test)           # prediction on test data

# Mean Absolute Error (MAE),
mae=mean_absolute_error(y_test,y_pred_test)
print("Mean Absolute Error (MAE)-Test:",mae.round(2))

# Mean Squared Error (MSE),
mse=mean_squared_error(y_test,y_pred_test)
print("Mean Squared Error (MSE)-Test:",mse.round(2))

# Root Mean Squared Error (RMSE),
#Square root of MSE gives RMSE
rmse=mse**(1/2)
print("Root Mean Squared Error (RMSE)-Test:",rmse.round(2))

# R² (R-Squared)
y2= r2_score(y_test, y_pred_test)
print("R squared Error-Test : ",y2)             # prediction on Test data

plt.scatter(y_train,y_pred_train,label='Train')
plt.scatter(y_test,y_pred_test,label='Test')
plt.title("XGB Regression")
plt.legend()
plt.show()

reg=pd.DataFrame(index=None, columns=['Model','Mean Absolute Error','Mean Squared Error','Root Mean Squared Error','R2 Score'])
regressors = [['LinearRegression',LinearRegression()],
              ['Ridge Regression',Ridge()],
              ['Lasso Regression',Lasso()],
              ['LogisticRegression',LogisticRegression()],
              ['DecisionTreeRegressor',DecisionTreeRegressor()],
              ['RandomForestRegressor',RandomForestRegressor(n_estimators=100)],
              ['KNeighborsRegressor',KNeighborsRegressor()],
              ['XGBRegressor',XGBRegressor()],
              ['GradientBoostingRegressor',GradientBoostingRegressor()],
              ['AdaBoostRegressor',AdaBoostRegressor()],
              ['BaggingRegressor',BaggingRegressor()]]

for mod in regressors:
    name = mod[0]
    Model = mod[1]
    Model.fit(x_train,y_train)

    y_pred_test=Model.predict(x_test)       # prediction on Test data

    mae=mean_absolute_error(y_test,y_pred_test)

    mse=mean_squared_error(y_test,y_pred_test)

    rmse=mse**(1/2)

    r2=r2_score(y_test,y_pred_test)

    reg=reg.append(pd.Series({'Model':name,'Mean Absolute Error':mae,'Mean Squared Error':mse,'Root Mean Squared Error':rmse,'R2 Score':r2}),ignore_index=True )

reg

plt.hist(y_pred_train, label='predicted train', color='blue')
plt.hist(y_pred_test, label="predicted test",edgecolor='black', color='yellow')
plt.legend()
plt.show()

plt.hist(y_train, label='train',color='blue')
plt.hist(y_test, label="test",edgecolor='black', color='orange')
plt.legend()
plt.show()

import pickle
# open a file, where you ant to store the data
file = open('Random_Forest_Model.pkl', 'wb')

# dump information to that file
pickle.dump(dr, file)